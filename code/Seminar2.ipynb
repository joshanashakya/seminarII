{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference from https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub('[^a-zA-Z ]', '', text)\n",
    "    text = re.sub('\\s+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    re_stop_words = re.compile(r'\\b(' + '|'.join(stop_words) + ')\\s')\n",
    "    return re_stop_words.sub('', text)\n",
    "\n",
    "def stem_text(text):\n",
    "    words = text.split(' ')\n",
    "    stemmer = PorterStemmer()\n",
    "    return ' '.join([stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_df = pd.read_csv('reuters_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_df['text'] = reuters_df['text'].apply(tokenize).apply(remove_stopwords).apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reuters_df['text'], reuters_df.iloc[:, 2:], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshana/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# vectorize data\n",
    "vectorizer = TfidfVectorizer(analyzer='word')\n",
    "\n",
    "xs = {'train': [], 'test': []}\n",
    "xs['train'] = vectorizer.fit_transform(X_train).toarray()\n",
    "xs['test'] = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "ys = {'train': [], 'test': []}\n",
    "ys['train'] = y_train.values\n",
    "ys['test'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['corn', 'cotton', 'rice', 'soybean', 'wheat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total\n",
      "560\n",
      "Training dataset\n",
      "392\n",
      "Testing dataset\n",
      "168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3827"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total')\n",
    "print(len(reuters_df))\n",
    "print('Training dataset')\n",
    "print(len(X_train))\n",
    "print('Testing dataset')\n",
    "print(len(X_test))\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset\n",
      "corn       149\n",
      "cotton      43\n",
      "rice        43\n",
      "soybean     77\n",
      "wheat      209\n",
      "dtype: int64\n",
      "\n",
      "Testing dataset\n",
      "corn       74\n",
      "cotton     19\n",
      "rice       24\n",
      "soybean    34\n",
      "wheat      78\n",
      "dtype: int64\n",
      "Training\n",
      "1    298\n",
      "2     66\n",
      "3     23\n",
      "4      3\n",
      "5      2\n",
      "Name: sum, dtype: int64\n",
      "\n",
      "Testing\n",
      "1    132\n",
      "2     18\n",
      "3     13\n",
      "4      3\n",
      "5      2\n",
      "Name: sum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset')\n",
    "print(y_train.sum())\n",
    "print('\\nTesting dataset')\n",
    "print(y_test.sum())\n",
    "\n",
    "y_train['sum'] = y_train.sum(axis = 1)\n",
    "print('Training')\n",
    "print(y_train['sum'].value_counts())\n",
    "y_test['sum'] = y_test.sum(axis = 1)\n",
    "print('\\nTesting')\n",
    "print(y_test['sum'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pystruct.github.io/auto_examples/multi_label.html#sphx-glr-auto-examples-multi-label-py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import hamming_loss\n",
    "from pystruct.learners import OneSlackSSVM\n",
    "from pystruct.models import MultiLabelClf\n",
    "from pystruct.datasets import load_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "n_labels = len(categories)\n",
    "print(n_labels)\n",
    "full = np.vstack([x for x in itertools.combinations(range(n_labels), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = MultiLabelClf(edges=full, inference_method='qpbo')\n",
    "full_model.n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ssvm = OneSlackSSVM(full_model, inference_cache=50, C=.1, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneSlackSSVM(C=0.1, break_on_bad=False, cache_tol='auto',\n",
       "       check_constraints=False, inactive_threshold=1e-05,\n",
       "       inactive_window=50, inference_cache=50, logger=None, max_iter=10000,\n",
       "       model=MultiLabelClf(n_states: 2, inference_method: qpbo), n_jobs=1,\n",
       "       negativity_constraint=None, show_loss_every=0, switch_to=None,\n",
       "       tol=0.01, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Fitting full model...')\n",
    "full_ssvm.fit(xs['train'], ys['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss full model: 0.067347\n",
      "Test loss full model: 0.134524\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loss full model: %f\"\n",
    "      % hamming_loss(ys['train'], np.vstack(full_ssvm.predict(xs['train']))))\n",
    "print(\"Test loss full model: %f\"\n",
    "      % hamming_loss(ys['test'], np.vstack(full_ssvm.predict(xs['test']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_ssvm.predict(xs['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(predictions):\n",
    "    to_display = []\n",
    "    for (actual, prediction) in zip(ys['test'], predictions):\n",
    "        actual_cats = []\n",
    "        predicted_cats = []\n",
    "        for (idx, category) in enumerate(actual):\n",
    "            if category != 0:\n",
    "                actual_cats.append(categories[idx])\n",
    "\n",
    "        for (idx, category) in enumerate(prediction):\n",
    "            if category != 0:\n",
    "                predicted_cats.append(categories[idx])\n",
    "        to_display.append((actual_cats, predicted_cats))\n",
    "    return to_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['corn'], ['corn']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'wheat'], ['corn']),\n",
       " (['soybean'], []),\n",
       " (['rice'], ['rice']),\n",
       " (['corn'], ['wheat']),\n",
       " (['corn', 'wheat'], ['corn']),\n",
       " (['rice'], []),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'cotton', 'rice', 'wheat'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['rice'], []),\n",
       " (['soybean'], ['soybean']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'soybean'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice', 'wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['cotton'], []),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'cotton', 'wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['wheat']),\n",
       " (['cotton'], []),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['cotton'], []),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], []),\n",
       " (['corn'], []),\n",
       " (['corn', 'cotton', 'soybean', 'wheat'], ['corn', 'soybean']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'wheat'], ['corn', 'wheat']),\n",
       " (['corn', 'cotton', 'wheat'], ['corn']),\n",
       " (['soybean'], []),\n",
       " (['soybean'], ['soybean']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'wheat'], ['corn', 'wheat']),\n",
       " (['corn', 'soybean'], ['corn', 'soybean', 'wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['soybean'], []),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], []),\n",
       " (['soybean'], ['soybean']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'soybean', 'wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'wheat'], ['wheat']),\n",
       " (['corn', 'cotton'], []),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], []),\n",
       " (['corn', 'wheat'], ['wheat']),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['rice'], ['rice']),\n",
       " (['corn', 'soybean', 'wheat'], []),\n",
       " (['corn'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice'], ['rice']),\n",
       " (['rice'], ['rice']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn', 'soybean', 'wheat'], ['wheat']),\n",
       " (['wheat'], ['corn', 'wheat']),\n",
       " (['soybean'], []),\n",
       " (['rice'], ['rice']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], []),\n",
       " (['corn'], []),\n",
       " (['soybean'], []),\n",
       " (['corn', 'wheat'], []),\n",
       " (['cotton'], ['cotton']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['cotton'], ['cotton']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], []),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice'], []),\n",
       " (['corn', 'cotton', 'rice'], ['wheat']),\n",
       " (['cotton', 'rice'], ['cotton']),\n",
       " (['wheat'], []),\n",
       " (['corn', 'wheat'], ['corn', 'wheat']),\n",
       " (['corn', 'rice'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['wheat']),\n",
       " (['rice', 'wheat'], ['wheat']),\n",
       " (['cotton'], ['cotton']),\n",
       " (['corn'], ['wheat']),\n",
       " (['rice'], ['wheat']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['corn'], ['corn']),\n",
       " (['soybean'], []),\n",
       " (['cotton'], []),\n",
       " (['wheat'], []),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice'], []),\n",
       " (['corn', 'cotton', 'rice', 'soybean'], []),\n",
       " (['cotton', 'rice'], []),\n",
       " (['corn'], ['corn']),\n",
       " (['cotton'], ['cotton']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['soybean'], ['soybean']),\n",
       " (['corn'], ['corn']),\n",
       " (['corn'], ['corn']),\n",
       " (['rice'], []),\n",
       " (['corn', 'rice', 'wheat'], []),\n",
       " (['corn', 'soybean'], []),\n",
       " (['corn', 'cotton', 'rice', 'soybean', 'wheat'], []),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['soybean'], ['wheat']),\n",
       " (['corn'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['corn', 'cotton', 'rice', 'soybean', 'wheat'], []),\n",
       " (['corn', 'soybean', 'wheat'], ['corn']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['wheat'], ['wheat']),\n",
       " (['rice'], ['rice']),\n",
       " (['corn', 'soybean'], ['corn']),\n",
       " (['soybean'], ['soybean'])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_display = display(predictions)\n",
    "to_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshana/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "fobj = open('example_text.txt', mode = 'r')\n",
    "data = fobj.read()\n",
    "fobj.close()\n",
    "example_text = stem_text(remove_stopwords(tokenize(data)))\n",
    "values = vectorizer.transform([example_text]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corn']\n"
     ]
    }
   ],
   "source": [
    "example_prediction = full_ssvm.predict(values)\n",
    "example_prediction_values = []\n",
    "for (idx, category) in enumerate(example_prediction[0]):\n",
    "    if category != 0:\n",
    "        example_prediction_values.append(categories[idx])\n",
    "print(example_prediction_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_list = list(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', 0.0517, 0.0757, 0.0414, 0.0510, 0.0594, 0.1003, 0.1101, 0.0717, 0.0939, 0.0763, 0.0440, 0.0717, 0.0560, 0.1003, 0.0661, 0.1003, 0.2115, 0.2113, 0.0450, 0.2532, 0.0429, 0.0731, 0.0360, 0.0560, 0.0828, 0.1564, 0.0606, 0.1385, 0.1763, 0.0329, 0.0893, 0.0803, 0.0489, 0.0893, 0.0460, 0.0871, 0.0844, 0.1418, 0.0717, 0.1066, 0.0565, 0.0546, 0.0782, 0.0692, 0.0893, 0.0546, 0.0880, 0.0620, 0.1003, 0.0767, 0.0463, 0.0420, 0.0613, 0.0628, 0.1984, 0.2007, 0.0420, 0.0782, 0.0582, 0.0652, 0.0746, 0.0537, 0.0560, 0.1003, 0.1003, 0.0939, 0.0696, 0.0542, 0.0455, 0.0893, 0.1026, 0.0661, 0.0565, 0.1464, 0.0161, 0.0365, 0.1723, 0.0746, 0.0939, 0.0893, 0.0576, 0.0782, 0.0939, 0.1241, 0.0704, 0.0939, 0.0857, 0.1588, 0.1003, 0.0985, 0.0717, 0.1877, 0.0764, 0.0803, 0.0801, 0.1489, 0.0571, 0.1003, 0.1435, 0.1072, 0.0828, 0.0798, 0.0652, 0.0972, 0.0904'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_val = [val for val in values_list if val != 0]\n",
    "str_val = ''\n",
    "for val in list_val:\n",
    "    str_val = '{}, {:.4f}'.format(str_val, val)\n",
    "str_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
